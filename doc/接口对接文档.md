# 接口对接文档

本文档说明哈工爷和上交爷需要实现的接口规范，以便与安迪的代码对接。

---

## 一、哈工爷（实习生A）需要实现的接口

### 1.1 数据加载器接口

**文件位置**: `src/environment/data_loader.py`

#### 1.1.1 `load_graph()` 函数

```python
def load_graph(dataset_name: str, opinion_init: str = "bimodal") -> nx.Graph:
    """
    加载图数据并初始化观点值
    
    Args:
        dataset_name: 数据集名称（如 "ego-Twitter"）
        opinion_init: 观点初始化方式
            - "bimodal": 双峰分布（一半节点 -0.8，一半节点 0.8）
            - "random": 随机分布（-1 到 1 之间均匀分布）
            - "uniform": 均匀分布
    
    Returns:
        graph: NetworkX 图对象，每个节点必须有 'opinion' 属性（float，范围 -1 到 1）
    
    要求:
        - 节点索引从 0 开始（0, 1, 2, ..., N-1）
        - 每个节点必须有 'opinion' 属性
        - 图可以是无向图或有向图（建议无向图）
    """
    pass
```

**示例**:
```python
graph = load_graph("ego-Twitter", opinion_init="bimodal")
print(graph.nodes[0]['opinion'])  # 应该输出 -0.8 或 0.8
```

#### 1.1.2 `generate_synthetic_graph()` 函数

```python
def generate_synthetic_graph(n_nodes: int = 50, graph_type: str = "BA") -> nx.Graph:
    """
    生成合成图（用于训练）
    
    Args:
        n_nodes: 节点数量（建议 30-50）
        graph_type: 图类型
            - "BA": Barabasi-Albert 无标度网络
    
    Returns:
        graph: NetworkX 图对象，每个节点必须有 'opinion' 属性
    """
    pass
```

---

### 1.2 观点动力学模型接口

**文件位置**: `src/environment/dynamics.py`

#### 1.2.1 `update_opinions()` 函数

```python
def update_opinions(
    graph: nx.Graph,
    model: str = "degroot",
    steps: int = 3,
    alpha: float = 0.5
) -> nx.Graph:
    """
    更新图中所有节点的观点值（使用观点动力学模型）
    
    Args:
        graph: 输入图（会被修改）
        model: 模型类型
            - "degroot": DeGroot 模型
            - "friedkin_johnsen": Friedkin-Johnsen 模型
        steps: 演化步数（建议 3-5 步）
        alpha: Friedkin-Johnsen 模型的固执度参数（0-1）
    
    Returns:
        updated_graph: 更新后的图（可以返回原图的副本或直接修改原图）
    
    公式参考:
        - DeGroot: x(t+1) = A_norm * x(t)
        - Friedkin-Johnsen: x(t+1) = alpha * A_norm * x(t) + (1-alpha) * x(0)
    
    性能要求:
        - 使用 scipy.sparse 稀疏矩阵进行计算
        - 避免双重 for 循环
    """
    pass
```

---

### 1.3 环境类接口

**文件位置**: `src/environment/opinion_env.py`

#### 1.3.1 `OpinionDynamicsEnv` 类

```python
import gymnasium
import networkx as nx

class OpinionDynamicsEnv(gymnasium.Env):
    """
    观点动力学环境
    
    这是一个 Gymnasium 环境，用于强化学习训练。
    """
    
    def __init__(
        self,
        graph: nx.Graph,
        budget: int,
        reward_fn: callable
    ):
        """
        初始化环境
        
        Args:
            graph: 初始图对象（NetworkX Graph）
            budget: 干预预算（每个 episode 最多选择 K 个节点）
            reward_fn: 奖励函数（由安迪提供）
                函数签名: reward_fn(state: nx.Graph, next_state: nx.Graph) -> float
        """
        pass
    
    def reset(self) -> nx.Graph:
        """
        重置环境，返回初始状态
        
        Returns:
            state: 初始图对象（NetworkX Graph）
        """
        pass
    
    def step(
        self,
        action_node: int,
        intervention_weight: float
    ) -> tuple:
        """
        执行一步动作
        
        Args:
            action_node: 被选中的节点索引（int，0 到 N-1）
            intervention_weight: 干预权重（float，0.0 到 1.0）
                由上交爷的 LLM 提供，表示干预强度
        
        Returns:
            next_state: 下一状态（NetworkX Graph）
            reward: 奖励值（float）
            done: 是否结束（bool）
            info: 额外信息（dict，可选）
        
        执行流程:
            1. 干预：修正选中节点的观点值
               公式: x_new = x_old * (1 - weight) + 0 * weight
               即：将节点观点值向中立（0）方向调整
            2. 演化：运行观点动力学模型 3-5 轮
               调用 update_opinions() 函数
            3. 计算奖励：调用 reward_fn(state, next_state)
            4. 判断是否结束：如果已选择 budget 个节点，done=True
        """
        pass
```

**使用示例**:
```python
from src.environment.opinion_env import OpinionDynamicsEnv
from src.agent.reward import compute_reward

# 创建环境
graph = load_graph("ego-Twitter")
env = OpinionDynamicsEnv(
    graph=graph,
    budget=10,
    reward_fn=lambda s, ns: compute_reward(s, ns, method="variance")
)

# 使用环境
state = env.reset()
next_state, reward, done, info = env.step(
    action_node=5,
    intervention_weight=0.6
)
```

---

## 二、上交爷（实习生B）需要实现的接口

### 2.1 LLM 控制器接口

**文件位置**: `src/llm/controller.py`

#### 2.1.1 `LLMController` 类

```python
class LLMController:
    """
    LLM 控制器，用于生成干预策略权重
    """
    
    def __init__(
        self,
        model_name: str = "Qwen/Qwen-7B",
        device: str = "cuda"
    ):
        """
        初始化 LLM 控制器
        
        Args:
            model_name: 模型名称或路径
            device: 设备（"cuda" 或 "cpu"）
        """
        pass
    
    def get_intervention_weight(
        self,
        node_id: int,
        graph: nx.Graph
    ) -> float:
        """
        根据节点及其邻居信息，生成干预权重
        
        Args:
            node_id: 目标节点索引（int）
            graph: 当前图对象（NetworkX Graph）
        
        Returns:
            weight: 干预权重（float，0.0 到 1.0 之间）
                0.0 表示不干预，1.0 表示完全干预（将观点值设为 0）
        
        实现步骤:
            1. 提取目标节点及其邻居的子图特征
            2. 生成文本描述（如："Node A has an extreme opinion (-0.9). 
               It connects to 5 neighbors with opposing views (avg 0.8)."）
            3. 构造 Prompt（参考 prompt_template.py）
            4. 调用 LLM（Qwen）
            5. 解析输出，提取浮点数（0.0-1.0）
        
        Prompt 示例:
            "Node A has an extreme opinion (-0.9). It connects to 5 neighbors 
            with opposing views (avg 0.8). You are a mediator. Determine the 
            'persuasiveness score' (0.0 to 1.0) required to moderate Node A. 
            Output only a float."
        """
        pass
```

**使用示例**:
```python
from src.llm.controller import LLMController
import networkx as nx

# 初始化控制器
llm_controller = LLMController(model_name="Qwen/Qwen-7B", device="cuda")

# 获取干预权重
graph = load_graph("ego-Twitter")
weight = llm_controller.get_intervention_weight(node_id=5, graph=graph)
print(f"干预权重: {weight}")  # 输出: 0.65
```

---

### 2.2 语义特征提取接口（可选）

**文件位置**: `src/llm/semantic_feature.py`

#### 2.2.1 `extract_semantic_embedding()` 函数

```python
def extract_semantic_embedding(
    node_id: int,
    graph: nx.Graph
) -> np.ndarray:
    """
    提取节点的语义嵌入特征（可选功能）
    
    如果算力允许，可以为每个节点生成语义嵌入，作为 RL 算法的输入特征。
    
    Args:
        node_id: 节点索引
        graph: 图对象
    
    Returns:
        embedding: 语义嵌入向量（numpy array）
    
    实现思路:
        1. 为节点生成"模拟推文"（使用 LLM）
        2. 将推文转换为 Embedding（使用 sentence-transformers 等）
        3. 返回嵌入向量
    """
    pass
```

---

### 2.3 可视化接口（可选）

**文件位置**: `src/visualization/gephi_exporter.py`

#### 2.3.1 `export_to_gexf()` 函数

```python
def export_to_gexf(
    graph: nx.Graph,
    filepath: str,
    color_by_opinion: bool = True
) -> None:
    """
    导出图到 Gephi 格式（.gexf）
    
    Args:
        graph: 图对象
        filepath: 输出文件路径
        color_by_opinion: 是否根据观点值分配颜色
    
    颜色映射:
        - -1.0（极左）→ #FF0000（深红）
        - 0.0（中立）→ #FFFFFF（白色）
        - 1.0（极右）→ #0000FF（深蓝）
        - 中间值线性插值
    """
    pass
```

---

## 三、接口对接检查清单

### 哈工爷检查清单

- [ ] 实现 `load_graph()` 函数，返回的图对象每个节点都有 `opinion` 属性
- [ ] 实现 `generate_synthetic_graph()` 函数，用于生成训练用的合成图
- [ ] 实现 `update_opinions()` 函数，使用稀疏矩阵优化性能
- [ ] 实现 `OpinionDynamicsEnv` 类，继承 `gymnasium.Env`
- [ ] `env.step()` 方法接收 `action_node`（int）和 `intervention_weight`（float）
- [ ] `env.step()` 返回 `(next_state, reward, done, info)` 元组
- [ ] 在 `env.step()` 中调用 `reward_fn(state, next_state)` 计算奖励

### 上交爷检查清单

- [ ] 实现 `LLMController` 类
- [ ] `get_intervention_weight()` 方法接收 `node_id`（int）和 `graph`（nx.Graph）
- [ ] `get_intervention_weight()` 返回 0.0-1.0 之间的浮点数
- [ ] 实现 Prompt 模板（参考 `prompt_template.py`）
- [ ] LLM 输出解析正确（提取浮点数）
- [ ] （可选）实现语义特征提取
- [ ] （可选）实现 Gephi 导出功能

---

## 四、测试接口的方法

### 测试哈工爷的接口

```python
# 测试数据加载
from src.environment.data_loader import load_graph, generate_synthetic_graph

graph = generate_synthetic_graph(n_nodes=50)
assert all('opinion' in graph.nodes[node] for node in graph.nodes())

# 测试环境
from src.environment.opinion_env import OpinionDynamicsEnv
from src.agent.reward import compute_reward

env = OpinionDynamicsEnv(
    graph=graph,
    budget=10,
    reward_fn=lambda s, ns: compute_reward(s, ns, method="variance")
)

state = env.reset()
next_state, reward, done, info = env.step(action_node=0, intervention_weight=0.5)
assert isinstance(reward, float)
assert isinstance(done, bool)
```

### 测试上交爷的接口

```python
# 测试 LLM Controller
from src.llm.controller import LLMController

llm_controller = LLMController()
weight = llm_controller.get_intervention_weight(node_id=0, graph=graph)
assert 0.0 <= weight <= 1.0
```

---

## 五、常见问题

**Q: 如果哈工爷的环境还没实现，安迪的代码能跑吗？**

A: 不能。训练脚本依赖 `OpinionDynamicsEnv` 类。建议先实现一个简化版本，确保接口正确。

**Q: 训练时一定要用 LLM 吗？**

A: 不需要。训练时可以使用随机权重加速训练。测试时才使用 LLM。

**Q: 图对象的节点索引必须从 0 开始吗？**

A: 是的。节点索引应该是连续的整数：0, 1, 2, ..., N-1。

**Q: `intervention_weight` 的具体含义是什么？**

A: 干预权重表示干预强度。0.0 表示不干预，1.0 表示完全干预（将观点值设为 0）。
公式：`x_new = x_old * (1 - weight) + 0 * weight`

---

**文档维护者**: 安迪  
**最后更新**: 2024-01-07



