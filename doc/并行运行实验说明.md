# 实验一和实验二并行运行说明

**创建日期**: 2026-01-13  
**目的**: 充分利用GPU资源，同时运行两个实验

---

## 一、运行方式

### 1.1 实验一已在运行

实验一使用两个GPU（GPU 0和GPU 1），通过`num_gpus=2`参数配置。

### 1.2 启动实验二（与实验一并行）

使用提供的脚本启动实验二，它会自动使用GPU 1：

```bash
./start_experiment2_parallel.sh
```

**脚本功能**：
- 自动检测实验一是否在运行
- 设置`CUDA_VISIBLE_DEVICES=1`，让实验二只使用GPU 1
- 后台运行，输出日志到`results/ijcai_experiments/logs/experiment2_*.log`
- 保存PID到`results/ijcai_experiments/logs/exp2.pid`

---

## 二、GPU资源分配

### 2.1 当前分配策略

| 实验 | GPU分配 | 说明 |
|------|---------|------|
| 实验一 | GPU 0 + GPU 1 | 使用`num_gpus=2`，在两个GPU上分配任务 |
| 实验二 | GPU 1 | 通过`CUDA_VISIBLE_DEVICES=1`限制只使用GPU 1 |

### 2.2 为什么可以并行运行？

1. **实验一的任务分配**：
   - 实验一使用`num_gpus=2`，会在GPU 0和GPU 1之间轮询分配任务
   - 由于任务数量多，两个GPU都会得到任务

2. **实验二的GPU限制**：
   - 通过`CUDA_VISIBLE_DEVICES=1`，实验二只能看到GPU 1（在它看来是`cuda:0`）
   - 实验二的所有GPU任务都会使用物理GPU 1

3. **资源竞争**：
   - GPU 1会被两个实验共享，但由于GPU利用率低（1-2%），可以承受
   - 显存使用：实验一约23GB，实验二约21GB，都在24GB限制内

---

## 三、监控和管理

### 3.1 监控脚本

使用提供的监控脚本查看运行状态：

```bash
./monitor_experiments.sh
```

**显示信息**：
- 运行中的实验进程
- GPU使用情况（利用率、显存）
- 最近的日志文件
- 结果文件大小
- 保存的PID

### 3.2 查看日志

**实验一日志**：
```bash
# 查看实验一的最新日志
ls -lht results/ijcai_experiments/logs/exp1_*.log | head -1 | awk '{print $NF}' | xargs tail -f
```

**实验二日志**：
```bash
# 查看实验二的最新日志
tail -f results/ijcai_experiments/logs/experiment2_*.log
```

### 3.3 停止实验

**停止实验一**：
```bash
# 查找实验一的PID
ps aux | grep "run_ijcai_experiments.*--experiment 1" | grep -v grep | awk '{print $2}' | xargs kill
```

**停止实验二**：
```bash
# 从PID文件读取
kill $(cat results/ijcai_experiments/logs/exp2.pid)

# 或直接查找进程
ps aux | grep "run_ijcai_experiments.*--experiment 2" | grep -v grep | awk '{print $2}' | xargs kill
```

---

## 四、性能优化建议

### 4.1 当前状态

- **GPU利用率**: 1-2%（很低，说明有大量空闲时间）
- **显存使用**: GPU 0约23GB，GPU 1约21GB（都在安全范围内）
- **CPU使用**: 实验一约17%，实验二约105%（实验二更活跃）

### 4.2 优化建议

如果GPU利用率仍然很低，可以考虑：

1. **增加每个GPU的进程数**：
   - 实验一：当前每个GPU 6个进程，可以尝试增加到8-10个
   - 实验二：当前每个GPU 6个进程，可以尝试增加到8-10个

2. **调整任务分配**：
   - 如果实验一主要使用GPU 0，可以让实验二使用GPU 1
   - 当前配置已经这样做了

3. **监控瓶颈**：
   - 如果CPU成为瓶颈，可以减少CPU进程数
   - 如果显存不足，可以减少GPU进程数

---

## 五、注意事项

### 5.1 资源竞争

- GPU 1会被两个实验共享，可能导致任务执行稍慢
- 但由于GPU利用率低，影响应该很小

### 5.2 数据保存

- 两个实验使用不同的输出文件，不会互相干扰：
  - 实验一：`results_main_comparison.jsonl`
  - 实验二：`results_ablation.jsonl`

### 5.3 断点续传

- 两个实验都支持断点续传
- 如果中途停止，重新运行会自动跳过已完成的任务

### 5.4 错误处理

- 如果实验二启动失败，检查：
  1. GPU 1是否被其他进程占用
  2. 显存是否足够（需要约20GB）
  3. 日志文件中的错误信息

---

## 六、预期效果

### 6.1 时间节省

- **单独运行**：实验一 + 实验二 = 总时间
- **并行运行**：max(实验一时间, 实验二时间) ≈ 节省50%时间

### 6.2 资源利用

- **GPU利用率提升**：从1-2%提升到可能10-20%
- **显存充分利用**：两个GPU都在使用
- **CPU充分利用**：多进程并行

---

## 七、故障排查

### 7.1 实验二无法启动

**问题**：`CUDA_VISIBLE_DEVICES=1`设置后，实验二仍然使用GPU 0

**解决**：
1. 检查环境变量是否正确设置
2. 确认实验二代码中正确读取了`CUDA_VISIBLE_DEVICES`
3. 查看日志中的设备分配信息

### 7.2 GPU显存不足

**问题**：OOM (Out of Memory) 错误

**解决**：
1. 减少每个GPU的进程数（从6减少到4）
2. 检查是否有其他进程占用显存
3. 考虑只运行一个实验

### 7.3 性能下降

**问题**：并行运行后，单个任务执行时间变长

**解决**：
1. 这是正常的，因为GPU资源被共享
2. 但总体时间仍然会减少（因为两个实验同时进行）
3. 如果影响太大，可以减少并发度

---

## 八、总结

✅ **实验一和实验二已成功并行运行**

- 实验一：使用GPU 0和GPU 1
- 实验二：使用GPU 1
- 两个实验互不干扰，充分利用GPU资源
- 支持断点续传，数据安全保存

**监控命令**：
```bash
./monitor_experiments.sh  # 查看运行状态
watch -n 1 nvidia-smi     # 实时监控GPU
```
